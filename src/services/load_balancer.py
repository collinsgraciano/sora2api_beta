"""Load balancing module"""
import asyncio
import random
from typing import Optional, Dict
from ..core.models import Token
from ..core.config import config
from .token_manager import TokenManager
from .token_lock import TokenLock
from .concurrency_manager import ConcurrencyManager
from ..core.logger import debug_logger

class LoadBalancer:
    """Token load balancer with random selection and image generation lock"""

    def __init__(self, token_manager: TokenManager, concurrency_manager: Optional[ConcurrencyManager] = None):
        self.token_manager = token_manager
        self.concurrency_manager = concurrency_manager
        # Use image timeout from config as lock timeout
        self.token_lock = TokenLock(lock_timeout=config.image_timeout)
        # è½®è¯¢æ¨¡å¼é” - åªä¿æŠ¤å†…å­˜ä¸­çš„é€‰æ‹©æ“ä½œï¼ˆæå¿«ï¼‰
        self._round_robin_lock = asyncio.Lock()
        # å†…å­˜ä¸­çš„ usage_count ç¼“å­˜ï¼Œé¿å…æ¯æ¬¡ä»æ•°æ®åº“è¯»å–
        self._usage_cache: Dict[int, int] = {}

    def _get_cached_usage(self, token_id: int, db_usage: int) -> int:
        """è·å–ç¼“å­˜ä¸­çš„ usage_countï¼Œå¦‚æœä¸å­˜åœ¨åˆ™ç”¨æ•°æ®åº“å€¼åˆå§‹åŒ–"""
        if token_id not in self._usage_cache:
            self._usage_cache[token_id] = db_usage
        return self._usage_cache[token_id]

    async def sync_usage_cache_from_db(self):
        """ä»æ•°æ®åº“åŒæ­¥ usage_count ç¼“å­˜ï¼ˆç”¨äºå¯åŠ¨æ—¶æˆ–é‡ç½®åï¼‰"""
        try:
            all_tokens = await self.token_manager.get_all_tokens()
            for token in all_tokens:
                self._usage_cache[token.id] = token.usage_count or 0
            debug_logger.log_info(f"[LOAD_BALANCER] âœ… å·²åŒæ­¥ {len(all_tokens)} ä¸ª Token çš„ usage_count ç¼“å­˜")
        except Exception as e:
            debug_logger.log_error(f"[LOAD_BALANCER] åŒæ­¥ usage_count ç¼“å­˜å¤±è´¥: {e}")

    async def reset_usage_cache(self):
        """é‡ç½®å†…å­˜ç¼“å­˜ï¼ˆä¸æ•°æ®åº“é‡ç½®åŒæ­¥ï¼‰"""
        self._usage_cache.clear()
        debug_logger.log_info("[LOAD_BALANCER] ğŸ”„ å·²æ¸…ç©º usage_count å†…å­˜ç¼“å­˜")

    async def _select_round_robin(self, available_tokens: list, for_image: bool = False, for_video: bool = False) -> Optional[Token]:
        """
        è½®è¯¢æ¨¡å¼é€‰æ‹© token - é«˜æ€§èƒ½ç‰ˆæœ¬
        
        ä½¿ç”¨å†…å­˜ç¼“å­˜çš„ usage_countï¼Œé”åªä¿æŠ¤"é€‰æ‹©+è®¡æ•°å¢åŠ "è¿™ä¸ªçº¯å†…å­˜æ“ä½œï¼ˆå¾®ç§’çº§ï¼‰
        ä¸ä¼šé˜»å¡å¹¶å‘è¯·æ±‚
        
        Args:
            available_tokens: å¯ç”¨çš„ token åˆ—è¡¨
            for_image: æ˜¯å¦ç”¨äºå›¾ç‰‡ç”Ÿæˆ
            for_video: æ˜¯å¦ç”¨äºè§†é¢‘ç”Ÿæˆ
            
        Returns:
            é€‰ä¸­çš„ tokenï¼Œæˆ– None
        """
        if not available_tokens:
            return None
        
        # é”å†…åªåšçº¯å†…å­˜æ“ä½œï¼Œæå¿«ï¼ˆå¾®ç§’çº§ï¼‰
        async with self._round_robin_lock:
            # ä½¿ç”¨å†…å­˜ç¼“å­˜è·å– usage_count
            token_with_usage = []
            for token in available_tokens:
                cached_usage = self._get_cached_usage(token.id, token.usage_count or 0)
                token_with_usage.append((token, cached_usage))
            
            # æŒ‰ usage_count å‡åºæ’åº
            token_with_usage.sort(key=lambda x: x[1])
            selected_token, current_usage = token_with_usage[0]
            
            # ç«‹å³åœ¨å†…å­˜ä¸­å¢åŠ è®¡æ•°ï¼ˆè¿™æ˜¯å¹¶å‘å®‰å…¨çš„å…³é”®ï¼‰
            self._usage_cache[selected_token.id] = current_usage + 1
        
        # é”å¤–å¼‚æ­¥æ›´æ–°æ•°æ®åº“ï¼ˆfire-and-forgetï¼Œä¸é˜»å¡ï¼‰
        asyncio.create_task(self._async_increment_db_usage(selected_token.id))
        
        debug_logger.log_info(f"[LOAD_BALANCER] ğŸ”„ è½®è¯¢æ¨¡å¼: é€‰ä¸­ Token {selected_token.id} ({selected_token.email}), usage_count: {current_usage} -> {current_usage + 1}")
        
        return selected_token

    async def _async_increment_db_usage(self, token_id: int):
        """å¼‚æ­¥æ›´æ–°æ•°æ®åº“ä¸­çš„ usage_countï¼ˆä¸é˜»å¡ä¸»æµç¨‹ï¼‰"""
        try:
            await self.token_manager.increment_usage_count(token_id)
        except Exception as e:
            debug_logger.log_error(f"[LOAD_BALANCER] å¼‚æ­¥æ›´æ–° usage_count å¤±è´¥: {e}")

    async def select_token(self, for_image_generation: bool = False, for_video_generation: bool = False, require_pro: bool = False) -> Optional[Token]:
        """
        Select a token using random load balancing

        Args:
            for_image_generation: If True, only select tokens that are not locked for image generation and have image_enabled=True
            for_video_generation: If True, filter out tokens with Sora2 quota exhausted (sora2_cooldown_until not expired), tokens that don't support Sora2, and tokens with video_enabled=False
            require_pro: If True, only select tokens with ChatGPT Pro subscription (plan_type="chatgpt_pro")

        Returns:
            Selected token or None if no available tokens
        """
        # Try to auto-refresh tokens expiring within 24 hours if enabled
        if config.at_auto_refresh_enabled:
            debug_logger.log_info(f"[LOAD_BALANCER] ğŸ”„ è‡ªåŠ¨åˆ·æ–°åŠŸèƒ½å·²å¯ç”¨ï¼Œå¼€å§‹æ£€æŸ¥Tokenè¿‡æœŸæ—¶é—´...")
            all_tokens = await self.token_manager.get_all_tokens()
            debug_logger.log_info(f"[LOAD_BALANCER] ğŸ“Š æ€»Tokenæ•°: {len(all_tokens)}")

            refresh_count = 0
            for token in all_tokens:
                if token.is_active and token.expiry_time:
                    from datetime import datetime
                    time_until_expiry = token.expiry_time - datetime.now()
                    hours_until_expiry = time_until_expiry.total_seconds() / 3600
                    # Refresh if expiry is within 24 hours
                    if hours_until_expiry <= 24:
                        debug_logger.log_info(f"[LOAD_BALANCER] ğŸ”” Token {token.id} ({token.email}) éœ€è¦åˆ·æ–°ï¼Œå‰©ä½™æ—¶é—´: {hours_until_expiry:.2f} å°æ—¶")
                        refresh_count += 1
                        await self.token_manager.auto_refresh_expiring_token(token.id)

            if refresh_count == 0:
                debug_logger.log_info(f"[LOAD_BALANCER] âœ… æ‰€æœ‰Tokenéƒ½æ— éœ€åˆ·æ–°")
            else:
                debug_logger.log_info(f"[LOAD_BALANCER] âœ… åˆ·æ–°æ£€æŸ¥å®Œæˆï¼Œå…±æ£€æŸ¥ {refresh_count} ä¸ªToken")

        active_tokens = await self.token_manager.get_active_tokens()

        if not active_tokens:
            return None

        # Filter for Pro tokens if required
        if require_pro:
            pro_tokens = [token for token in active_tokens if token.plan_type == "chatgpt_pro"]
            if not pro_tokens:
                return None
            active_tokens = pro_tokens

        # If for video generation, filter out tokens with Sora2 quota exhausted and tokens without Sora2 support
        if for_video_generation:
            from datetime import datetime
            available_tokens = []
            for token in active_tokens:
                # Skip tokens that don't have video enabled
                if not token.video_enabled:
                    continue

                # Skip tokens that don't support Sora2
                if not token.sora2_supported:
                    continue

                # Check if Sora2 cooldown has expired and refresh if needed
                if token.sora2_cooldown_until and token.sora2_cooldown_until <= datetime.now():
                    await self.token_manager.refresh_sora2_remaining_if_cooldown_expired(token.id)
                    # Reload token data after refresh
                    token = await self.token_manager.db.get_token(token.id)

                # Skip tokens that are in Sora2 cooldown (quota exhausted)
                if token and token.sora2_cooldown_until and token.sora2_cooldown_until > datetime.now():
                    continue

                if token:
                    available_tokens.append(token)

            if not available_tokens:
                return None

            active_tokens = available_tokens

        # If for image generation, filter out locked tokens and tokens without image enabled
        if for_image_generation:
            available_tokens = []
            for token in active_tokens:
                # Skip tokens that don't have image enabled
                if not token.image_enabled:
                    continue

                if not await self.token_lock.is_locked(token.id):
                    # Check concurrency limit if concurrency manager is available
                    if self.concurrency_manager and not await self.concurrency_manager.can_use_image(token.id):
                        continue
                    available_tokens.append(token)

            if not available_tokens:
                return None

            # Determine selection strategy based on admin config
            scheduling_mode = await self.token_manager.get_scheduling_mode()
            
            if scheduling_mode == "round_robin":
                # ä½¿ç”¨äº’æ–¥é”ä¿æŠ¤çš„è½®è¯¢é€‰æ‹©
                return await self._select_round_robin(available_tokens, for_image=True)
            else:
                return random.choice(available_tokens)
        else:
            # For video generation, check concurrency limit
            if for_video_generation and self.concurrency_manager:
                available_tokens = []
                for token in active_tokens:
                    if await self.concurrency_manager.can_use_video(token.id):
                        available_tokens.append(token)
                if not available_tokens:
                    return None
                
                # Determine selection strategy based on admin config
                scheduling_mode = await self.token_manager.get_scheduling_mode()
                if scheduling_mode == "round_robin":
                    # ä½¿ç”¨äº’æ–¥é”ä¿æŠ¤çš„è½®è¯¢é€‰æ‹©
                    return await self._select_round_robin(available_tokens, for_video=True)
                else:
                    return random.choice(available_tokens)
            else:
                # For video generation without concurrency manager
                # Also apply scheduling mode
                scheduling_mode = await self.token_manager.get_scheduling_mode()
                if scheduling_mode == "round_robin":
                    # ä½¿ç”¨äº’æ–¥é”ä¿æŠ¤çš„è½®è¯¢é€‰æ‹©
                    return await self._select_round_robin(active_tokens, for_video=for_video_generation)
                else:
                    return random.choice(active_tokens)

